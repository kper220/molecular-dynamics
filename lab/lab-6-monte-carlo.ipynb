{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mpl_toolkits.mplot3d\n",
    "import numpy as np\n",
    "from scipy import integrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10 ** 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rejection Sampling\n",
    "\n",
    "Sampling from the uniform distribution $X\\sim U(a, b)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.uniform(0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling from an arbitrary function $X\\sim\\rho$, where $\\rho$ is a density defined on the finite, connected domain $(a, b)$. This uses principles of *rejection sampling*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_arbitrary_function(rho, a, b, \n",
    "                              n = 1, \n",
    "                              phi = lambda x:x,\n",
    "                              sampling = np.random.uniform):\n",
    "    # phi is some operation.\n",
    "    \n",
    "    if n == 1:\n",
    "        rejected = True\n",
    "        while rejected:\n",
    "            \n",
    "            # different sampling methods can be chosen here.\n",
    "            x = sampling(a, b)\n",
    "            \n",
    "            # case of acceptance.\n",
    "            if rho(x) >= np.random.uniform(0, 1):\n",
    "                rejected = False\n",
    "                return phi(x)\n",
    "            \n",
    "            pass\n",
    "        pass\n",
    "    else:\n",
    "        return np.array([sample_arbitrary_function(rho, a, b, n = 1, phi = phi) for _ in range(n)])\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstration with the sine function, defined on $(0, \\pi)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = lambda x:1/2*np.sin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_arbitrary_function(p, 0, np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = 0, np.pi\n",
    "\n",
    "solution = sample_arbitrary_function(p, a, b, n = n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(solution, 50, density = True)\n",
    "\n",
    "xx = np.linspace(0, np.pi, 100)\n",
    "plt.plot(xx, p(xx))\n",
    "\n",
    "plt.title('Histogram')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte Carlo Approximation\n",
    "\n",
    "Let $x_1, \\cdots, x_n\\sim p$, then the sample mean $\\hat{\\mu}_n = \\dfrac{1}{n}\\sum_{i = 1}^n\\phi(x_i)$ is a basic Monte Carlo estimator of $\\mathbb{E}\\phi(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importance sampling\n",
    "\n",
    "Let $X\\sim p$. Then the expectation $\\mathbb{E}\\phi(x) = \\int_\\Omega\\phi(x)p(x)dx\\approx\\dfrac{1}{n}\\sum_{i = 1}^n\\phi(x_i)$. Let $q(x)$ be a proposal density such that $q(x) = 0$ if and only if $p(x) = 0$ (absolute continuity). Then $\\mathbb{E}\\phi(x) \\approx\\dfrac{1}{n}\\sum_{i = 1}^n\\phi(y_i)w(y_i)$, where $w(y) = \\dfrac{p(y)}{q(y)}$ and $Y\\sim q$.\n",
    "\n",
    "**Principle**: choose $q(x)$ such that $q(x)\\propto\\vert\\phi(x)\\vert p(x)$, i.e. $q$ places more weight on regions where $\\vert\\phi(x)\\vert p(x)$ is large.\n",
    "\n",
    "However, usually we can't find such an exact $q$. Because if we did, we would have also found the partition function of $\\phi(x)p(x)$, and that would be the desired expectation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstration\n",
    "\n",
    "From the density $p(x) = \\dfrac{1}{2}\\sin(x)$ we sample $X$. Let $\\phi(x) = x^2$. We first find the expectation $\\mathbb{E}\\phi(x)$ analytically, and yield $\\dfrac{1}{2}(\\pi^2-4)$. Next, we sample the approximation directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theoretical_expectation = 1/2*(np.pi**2 - 4)\n",
    "print(theoretical_expectation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = lambda x:np.power(x, 2)\n",
    "\n",
    "direct_sample = sample_arbitrary_function(p, a, b, n = n, phi = phi)\n",
    "plt.hist(direct_sample, 50, density = True)\n",
    "plt.show()\n",
    "\n",
    "direct_sample_mean = np.average(direct_sample)\n",
    "\n",
    "print('Sample from direct average: {}'.format(direct_sample_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $q(x) \\propto \\vert\\phi(x)\\vert p(x) = \\dfrac{x^2}{2}\\sin(x)$ be a density function, then $q =\\dfrac{\\sin(x)}{2Z}$, where the partition function $Z = \\dfrac{\\pi^2 - 4}{2}$, is a legal density function. We can varify absolute continuity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = lambda x:np.power(x, 2)/(np.power(np.pi, 2) - 4)*np.sin(x)\n",
    "\n",
    "new_sampling = lambda a, b:sample_arbitrary_function(q, a, b)\n",
    "sample = sample_arbitrary_function(q, a, b, n = n, sampling = new_sampling)\n",
    "\n",
    "plt.hist(sample, 50, density = True)\n",
    "\n",
    "xx = np.linspace(0, np.pi)\n",
    "plt.plot(xx, q(xx))\n",
    "\n",
    "plt.title('Map of proposal density function')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that we defined $q(x) = Z^{-1}\\phi(x)p(x)$. Therefore, $\\mathbb{E}\\phi(x) = \\dfrac{1}{n}\\sum_{i = 1}^n\\phi(x_i)w(x_i) = \\dfrac{\\pi^2 - 4}{2}$ is trivially obtained. In this case, our sampling does not influence the outcome of the result, since $\\phi w$ is a constant function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov Chain Monte Carlo\n",
    "\n",
    "A Markov chain which is irreducible, has a stationary distribution $\\pi$, and is aperiodic, is an *ergodic* Markov chain.\n",
    "\n",
    "I think [Wikipedia](https://en.wikipedia.org/wiki/Markov_chain) explains aperiodicity best:\n",
    "\n",
    "> A state $i$ has period $k$, if any return to state $i$ must occur in multiples of $k$ time steps. [...] If $k = 1$, then the state is said to be *aperiodic*.\n",
    "\n",
    "Also refer to this [post](https://math.stackexchange.com/questions/1227869/period-of-a-markov-chain-why-is-this-one-aperiodic) on my shared misconception with the asker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markov chain model algorithm\n",
    "\n",
    "We design an algorithm modeling the movement of a particle in a Markov chain with an $n\\times n$ transition matrix $M$.\n",
    "\n",
    "Suppose we have a Markov matrix $M = \\begin{bmatrix}.25 & .75\\\\.4 & .6\\end{bmatrix}$, then a cumulative probability matrix is $C = \\begin{bmatrix}.25 & 1\\\\.4 & 1\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def markov_chain_cumulative_matrix(transition_matrix):\n",
    "    n = len(transition_matrix)\n",
    "    solution = [[None for _ in range(n)] for _ in range(n)]\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if j == 0:\n",
    "                solution[i][0] = transition_matrix[i][0]\n",
    "                pass\n",
    "            else:\n",
    "                solution[i][j] = solution[i][j-1] + transition_matrix[i][j]\n",
    "                pass\n",
    "            pass\n",
    "        pass\n",
    "    return np.array(solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A demonstration of the cumulative matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markov_chain_cumulative_matrix(np.array([\n",
    "    [.25, .75],\n",
    "    [.4, .6]\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reflective random walk matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reflective_random_walk = np.array([\n",
    "    [.0, 1., 0., 0., .0, .0],\n",
    "    [.5, .0, .5, .0, .0, .0],\n",
    "    [.0, .5, .0, .5, .0, .0],\n",
    "    [.0, .0, .5, .0, .5, .0],\n",
    "    [.0, .0, .0, .5, .0, .5],\n",
    "    [.0, .0, .0, .0, 1., .0]\n",
    "])\n",
    "\n",
    "markov_chain_cumulative_matrix(reflective_random_walk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def markov_chain_sample(cumulative_matrix, current_value, dim):\n",
    "    # extract relevant probabilities.\n",
    "    \n",
    "    cumulative_probabilities = cumulative_matrix[current_value]\n",
    "    \n",
    "    # sample u.\n",
    "    u = np.random.uniform(0, 1)\n",
    "    \n",
    "    # find greatest upper bound.\n",
    "    for j in range(dim):\n",
    "        if u <= cumulative_probabilities[j]:\n",
    "            return j\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling the next value in a Markov chain with current value $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markov_chain_sample(markov_chain_cumulative_matrix(reflective_random_walk), 2, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def markov_chain(transition_matrix, initial_state, n):\n",
    "    cumulative_matrix = markov_chain_cumulative_matrix(transition_matrix)\n",
    "    dim = len(transition_matrix)\n",
    "    \n",
    "    # standardize arguments.\n",
    "    transition_matrix = np.array(transition_matrix)\n",
    "    \n",
    "    # construct solution space.\n",
    "    solution = [None for _ in range(n)]\n",
    "    \n",
    "    # sample from the Markov chain.\n",
    "    for i in range(n):\n",
    "        # initial condition.\n",
    "        if i == 0:\n",
    "            solution[0] = initial_state\n",
    "            pass\n",
    "        \n",
    "        else:\n",
    "            current_value = solution[i-1]\n",
    "            solution[i] = markov_chain_sample(cumulative_matrix, current_value, dim)\n",
    "        pass\n",
    "    \n",
    "    return np.array(solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_matrix = np.array([\n",
    "    [.25, .75],\n",
    "    [.4, .6]\n",
    "])\n",
    "initial_state = 0\n",
    "solution = markov_chain(transition_matrix, initial_state, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_of_first_bin = -0.5\n",
    "right_of_last_bin = 2.5\n",
    "\n",
    "plt.hist(solution, np.arange(left_of_first_bin, right_of_last_bin, 1), density = True)\n",
    "plt.title('Markov chain state histogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflective random walks\n",
    "\n",
    "A reflective random walk is a Markov process. Particles in the random walk are bounded on both sides, and move randomly in between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = 0\n",
    "solution = markov_chain(reflective_random_walk, initial_state, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_of_first_bin = -.5\n",
    "right_of_last_bin = 6.5\n",
    "\n",
    "plt.hist(solution, np.arange(left_of_first_bin, right_of_last_bin, 1), density = True)\n",
    "plt.title('Reflective random walk state histogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detailed balance\n",
    "\n",
    "A probability mass function $\\pi$ on $\\mathcal{X}$ satisfies *detailed balance* with respect to a transition matrix $T = (T_{ab})$, if $\\pi_aT_{ab} = \\pi_bT_{ba}$ for all $a, b\\in\\mathcal{X}$. Furthermore, detailed balance implies that $\\pi$ is a stationary distribution, i.e. $\\pi T = \\pi$. Detailed balance is also known as reversibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metropolis Algorithm\n",
    "\n",
    "Consider a pmf $\\pi$ on countable $\\mathcal{X}$ and an observable $\\phi:\\mathcal{X}\\to\\mathbb{R}$. Our goal is to approximate $\\mathbb{E}\\phi(x)$ where $x\\sim\\pi$, and where directly sampling is prohibitively expensive.\n",
    "\n",
    "Let $Q$ be a symmetric, stochastic matrix, termed the *proposal matrix*, such that $Q = (Q_{ab}: a, b\\in\\mathcal{X})$. Let $\\tilde{\\pi} = Z\\pi$. Computing $\\tilde{\\pi}(x)$ without having to compute $Z$ is sufficient in implementing the Metropolis algorithm.\n",
    "\n",
    "The algorithm is described as follows:\n",
    "\n",
    "1. Choose a proposal matrix $Q$,\n",
    "2. Set initial value $x_0\\sim\\mathcal{X}$,\n",
    "3. For $i = 0, \\cdots, n - 1$, sample $x\\sim Q_{x_ix}$ and $u\\sim U(0, 1)$. If $u < \\dfrac{\\tilde{\\pi}(x)}{\\tilde{\\pi}(x_i)}$, then $x_{i + 1} = x$. Otherwise, $x_{i + 1} = x_i$.\n",
    "\n",
    "**Principle**: it is found that the identity matrix $I$ is not a suitable proposal matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modified reflective walk algorithm\n",
    "\n",
    "Let a Markov chain be described by the transition matrix, $T = \\begin{bmatrix}.5 & .5 & 0\\\\.25 & .5 & .25\\\\0 & .5 & .5\\end{bmatrix}$. The matrix is irreducible. Next, there exists a stationary pmf $\\pi = \\begin{bmatrix}.25 & .5 & .25\\end{bmatrix}$. Furthermore, the period for any state is $1$. Therefore, this matrix is ergodic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reflective_walk_modified = np.array([\n",
    "    [.5, .5, .0],\n",
    "    [.25, .5, .25],\n",
    "    [.0, .5, .5]\n",
    "])\n",
    "pi = np.array([[.25, .5, .25]])\n",
    "\n",
    "# we can confirm that pi is indeed stationary with respect to T.\n",
    "np.dot(pi, reflective_walk_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial state.\n",
    "initial_state = 0\n",
    "solution = markov_chain(reflective_walk_modified, initial_state, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "left_of_first_bin = -.5\n",
    "right_of_last_bin = 3.5\n",
    "plt.hist(solution, np.arange(left_of_first_bin, right_of_last_bin, 1), density = True)\n",
    "plt.title('Modified walk distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let our proposal matrix be $\\begin{bmatrix}.5 & .25 & .25\\\\.25 & .5 & .25\\\\.25 & .25 & .5\\end{bmatrix}$. We can let $\\tilde{\\pi}$ be any pmf proportional to $\\pi$, so let's just have $\\tilde{\\pi} = \\begin{bmatrix} 1 & 2 & 1\\end{bmatrix}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposal_matrix = np.array([\n",
    "    [.5, .25, .25],\n",
    "    [.25, .5, .25],\n",
    "    [.25, .25, .5]\n",
    "])\n",
    "\n",
    "pi_tilde = np.array([[1, 2, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = 0\n",
    "cumulative_matrix = markov_chain_cumulative_matrix(proposal_matrix)\n",
    "dim = len(proposal_matrix)\n",
    "\n",
    "# solution set.\n",
    "solution = [None for _ in range(n)]\n",
    "\n",
    "# compute solution.\n",
    "for i in range(n):\n",
    "    if i == 0:\n",
    "        solution[0] = initial_state\n",
    "        pass\n",
    "    else:\n",
    "        current_value = solution[i-1]\n",
    "        x = markov_chain_sample(cumulative_matrix, current_value, dim)\n",
    "        u = np.random.uniform(0, 1)\n",
    "\n",
    "        if u <= pi_tilde[0][x] / pi_tilde[0][current_value]:\n",
    "            solution[i] = x\n",
    "            pass\n",
    "        else:\n",
    "            solution[i] = current_value\n",
    "            pass\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_of_first_bin = -.5\n",
    "right_of_last_bin = 3.5\n",
    "\n",
    "plt.hist(solution, np.arange(left_of_first_bin, right_of_last_bin, 1), density = True)\n",
    "plt.title('Modified walk distribution (Metropolis)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metropolis Hastings Algorithm\n",
    "\n",
    "Let $f(x)$ be proportional to the target density up to a normalizing constant, and set the current value $x^j$. We sample from the proposal density $x^*\\sim q(x\\vert x^j)$. The probability that $x^*$ is accepted is $\\rho(x^j, x^*) = \\min\\bigg\\{1, \\dfrac{f(x^*)}{f(x^j)}\\dfrac{q(x^j\\vert x^*)}{q(x^*\\vert x^j)}\\bigg\\}$. If $x^*$ is accepted, then $x^{j+1} = x^*$; otherwise $x^{j+1} = x^j$.\n",
    "\n",
    "**Demonstration**: consider the truncated normal distribution $N(5, 9)I(1\\leq x\\leq 6)$. The unnormalized target density is $f(x)\\propto\\exp(-(x-5)^2/18)I(1\\leq x\\leq 6)$, and we choose a proposal distribution $q(x\\vert x^j) = N(x\\vert x^j, 1)$ and let $x^0 = 5$. (Video: [Niemi](https://www.youtube.com/watch?v=VGRVRjr0vyw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_constant = integrate.quad(lambda x:np.exp(-(x-5)**2/18)*(1<x<6), 1, 6)[0]\n",
    "def target_dist(x):\n",
    "    if isinstance(x, np.ndarray):\n",
    "        return np.array([target_dist(_x) for _x in x])\n",
    "    return np.exp(-(x-5)**2/18)*(1<x<6)/normalization_constant\n",
    "\n",
    "proposal_dist = lambda x, mu:np.exp(-(x-mu)**2)\n",
    "proposal_dist_sample = lambda x:np.random.normal(x, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metropolis_hastings_random_walk(m):\n",
    "    # this is a demonstration function.\n",
    "    # m is the number of trials.\n",
    "    x_init = 5\n",
    "    solution = [None for _ in range(m)]\n",
    "    for i in range(m):\n",
    "        if i == 0:\n",
    "            solution[0] = x_init\n",
    "            pass\n",
    "        else:\n",
    "            current_value = solution[i-1]\n",
    "            sampled_value = proposal_dist_sample(current_value)\n",
    "            acceptance_probability = min(1, (target_dist(sampled_value)*proposal_dist(current_value, sampled_value))/(target_dist(current_value)*proposal_dist(sampled_value, current_value)))\n",
    "            u = np.random.uniform(0, 1)\n",
    "            # conditions for accept.\n",
    "            if u <= acceptance_probability:\n",
    "                solution[i] = sampled_value\n",
    "                pass\n",
    "            # conditions for reject.\n",
    "            else:\n",
    "                solution[i] = current_value\n",
    "                pass\n",
    "            pass\n",
    "        pass\n",
    "    return solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison of the Metropolis-Hastings algorithm at different densities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xx = np.linspace(1, 6, 100)\n",
    "\n",
    "s = 6 # number of densities.\n",
    "i = 1 # initial subplot index\n",
    "\n",
    "f, axs = plt.subplots(2,2,figsize=(6.4 * 2, 4.8 * s))\n",
    "\n",
    "for k in range(1, s + 1):\n",
    "    solution = metropolis_hastings_random_walk(10 ** k)\n",
    "    \n",
    "    plt.subplot(s, 2, i)\n",
    "    plt.plot(solution)\n",
    "    plt.title('Evolution ({} iterations)'.format(10 ** k))\n",
    "    i += 1\n",
    "    \n",
    "    plt.subplot(s, 2, i)\n",
    "    plt.hist(solution, 100, density = True)\n",
    "    plt.step(xx, target_dist(xx), label = 'target')\n",
    "    plt.title('Histogram ({} iterations)'.format(10**k))\n",
    "    plt.legend()\n",
    "    i += 1\n",
    "    pass\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
