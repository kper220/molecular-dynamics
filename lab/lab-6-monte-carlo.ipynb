{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mpl_toolkits.mplot3d\n",
    "import numpy as np\n",
    "from scipy import integrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10 ** 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rejection Sampling\n",
    "\n",
    "Sampling from the uniform distribution $X\\sim U(a, b)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.uniform(0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling from an arbitrary function $X\\sim\\rho$, where $\\rho$ is a density defined on the finite, connected domain $(a, b)$. This uses principles of *rejection sampling*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_arbitrary_function(rho, a, b, \n",
    "                              n = 1, \n",
    "                              phi = lambda x:x,\n",
    "                              sampling = np.random.uniform):\n",
    "    # phi is some operation.\n",
    "    \n",
    "    if n == 1:\n",
    "        rejected = True\n",
    "        while rejected:\n",
    "            \n",
    "            # different sampling methods can be chosen here.\n",
    "            x = sampling(a, b)\n",
    "            \n",
    "            # case of acceptance.\n",
    "            if rho(x) >= np.random.uniform(0, 1):\n",
    "                rejected = False\n",
    "                return phi(x)\n",
    "            \n",
    "            pass\n",
    "        pass\n",
    "    else:\n",
    "        return np.array([sample_arbitrary_function(rho, a, b, n = 1, phi = phi) for _ in range(n)])\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstration with the sine function, defined on $(0, \\pi)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = lambda x:1/2*np.sin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_arbitrary_function(p, 0, np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = 0, np.pi\n",
    "\n",
    "solution = sample_arbitrary_function(p, a, b, n = n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(solution, 50, density = True)\n",
    "\n",
    "xx = np.linspace(0, np.pi, 100)\n",
    "plt.plot(xx, p(xx))\n",
    "\n",
    "plt.title('Histogram')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte Carlo Approximation\n",
    "\n",
    "Let $x_1, \\cdots, x_n\\sim p$, then the sample mean $\\hat{\\mu}_n = \\dfrac{1}{n}\\sum_{i = 1}^n\\phi(x_i)$ is a basic Monte Carlo estimator of $\\mathbb{E}\\phi(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importance sampling\n",
    "\n",
    "Let $X\\sim p$. Then the expectation $\\mathbb{E}\\phi(x) = \\int_\\Omega\\phi(x)p(x)dx\\approx\\dfrac{1}{n}\\sum_{i = 1}^n\\phi(x_i)$. Let $q(x)$ be a proposal density such that $q(x) = 0$ if and only if $p(x) = 0$ (absolute continuity). Then $\\mathbb{E}\\phi(x) \\approx\\dfrac{1}{n}\\sum_{i = 1}^n\\phi(y_i)w(y_i)$, where $w(y) = \\dfrac{p(y)}{q(y)}$ and $Y\\sim q$.\n",
    "\n",
    "**Principle**: choose $q(x)$ such that $q(x)\\propto\\vert\\phi(x)\\vert p(x)$, i.e. $q$ places more weight on regions where $\\vert\\phi(x)\\vert p(x)$ is large.\n",
    "\n",
    "However, usually we can't find such an exact $q$. Because if we did, we would have also found the partition function of $\\phi(x)p(x)$, and that would be the desired expectation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstration\n",
    "\n",
    "From the density $p(x) = \\dfrac{1}{2}\\sin(x)$ we sample $X$. Let $\\phi(x) = x^2$. We first find the expectation $\\mathbb{E}\\phi(x)$ analytically, and yield $\\dfrac{1}{2}(\\pi^2-4)$. Next, we sample the approximation directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theoretical_expectation = 1/2*(np.pi**2 - 4)\n",
    "print(theoretical_expectation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = lambda x:np.power(x, 2)\n",
    "\n",
    "direct_sample = sample_arbitrary_function(p, a, b, n = n, phi = phi)\n",
    "plt.hist(direct_sample, 50, density = True)\n",
    "plt.show()\n",
    "\n",
    "direct_sample_mean = np.average(direct_sample)\n",
    "\n",
    "print('Sample from direct average: {}'.format(direct_sample_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $q(x) \\propto \\vert\\phi(x)\\vert p(x) = \\dfrac{x^2}{2}\\sin(x)$ be a density function, then $q =\\dfrac{\\sin(x)}{2Z}$, where the partition function $Z = \\dfrac{\\pi^2 - 4}{2}$, is a legal density function. We can varify absolute continuity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = lambda x:np.power(x, 2)/(np.power(np.pi, 2) - 4)*np.sin(x)\n",
    "\n",
    "new_sampling = lambda a, b:sample_arbitrary_function(q, a, b)\n",
    "sample = sample_arbitrary_function(q, a, b, n = n, sampling = new_sampling)\n",
    "\n",
    "plt.hist(sample, 50, density = True)\n",
    "\n",
    "xx = np.linspace(0, np.pi)\n",
    "plt.plot(xx, q(xx))\n",
    "\n",
    "plt.title('Map of proposal density function')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that we defined $q(x) = Z^{-1}\\phi(x)p(x)$. Therefore, $\\mathbb{E}\\phi(x) = \\dfrac{1}{n}\\sum_{i = 1}^n\\phi(x_i)w(x_i) = \\dfrac{\\pi^2 - 4}{2}$ is trivially obtained. In this case, our sampling does not influence the outcome of the result, since $\\phi w$ is a constant function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov Chain Monte Carlo\n",
    "\n",
    "A Markov chain which is irreducible, has a stationary distribution $\\pi$, and is aperiodic, is an *ergodic* Markov chain.\n",
    "\n",
    "I think [Wikipedia](https://en.wikipedia.org/wiki/Markov_chain) explains aperiodicity best:\n",
    "\n",
    "> A state $i$ has period $k$, if any return to state $i$ must occur in multiples of $k$ time steps. [...] If $k = 1$, then the state is said to be *aperiodic*.\n",
    "\n",
    "Also refer to this [post](https://math.stackexchange.com/questions/1227869/period-of-a-markov-chain-why-is-this-one-aperiodic) on my shared misconception with the asker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markov chain model algorithm\n",
    "\n",
    "We design an algorithm modeling the movement of a particle in a Markov chain with an $n\\times n$ transition matrix $M$.\n",
    "\n",
    "Suppose we have a Markov matrix $M = \\begin{bmatrix}.25 & .75\\\\.4 & .6\\end{bmatrix}$, then a cumulative probability matrix is $C = \\begin{bmatrix}.25 & 1\\\\.4 & 1\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def markov_chain_cumulative_matrix(transition_matrix):\n",
    "    n = len(transition_matrix)\n",
    "    solution = [[None for _ in range(n)] for _ in range(n)]\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if j == 0:\n",
    "                solution[i][0] = transition_matrix[i][0]\n",
    "                pass\n",
    "            else:\n",
    "                solution[i][j] = solution[i][j-1] + transition_matrix[i][j]\n",
    "                pass\n",
    "            pass\n",
    "        pass\n",
    "    return np.array(solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A demonstration of the cumulative matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markov_chain_cumulative_matrix(np.array([\n",
    "    [.25, .75],\n",
    "    [.4, .6]\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reflective random walk matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reflective_random_walk = np.array([\n",
    "    [.0, 1., 0., 0., .0, .0],\n",
    "    [.5, .0, .5, .0, .0, .0],\n",
    "    [.0, .5, .0, .5, .0, .0],\n",
    "    [.0, .0, .5, .0, .5, .0],\n",
    "    [.0, .0, .0, .5, .0, .5],\n",
    "    [.0, .0, .0, .0, 1., .0]\n",
    "])\n",
    "\n",
    "markov_chain_cumulative_matrix(reflective_random_walk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def markov_chain_sample(cumulative_matrix, current_value, dim):\n",
    "    # extract relevant probabilities.\n",
    "    \n",
    "    cumulative_probabilities = cumulative_matrix[current_value]\n",
    "    \n",
    "    # sample u.\n",
    "    u = np.random.uniform(0, 1)\n",
    "    \n",
    "    # find greatest upper bound.\n",
    "    for j in range(dim):\n",
    "        if u <= cumulative_probabilities[j]:\n",
    "            return j\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling the next value in a Markov chain with current value $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markov_chain_sample(markov_chain_cumulative_matrix(reflective_random_walk), 2, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def markov_chain(transition_matrix, initial_state, n):\n",
    "    cumulative_matrix = markov_chain_cumulative_matrix(transition_matrix)\n",
    "    dim = len(transition_matrix)\n",
    "    \n",
    "    # standardize arguments.\n",
    "    transition_matrix = np.array(transition_matrix)\n",
    "    \n",
    "    # construct solution space.\n",
    "    solution = [None for _ in range(n)]\n",
    "    \n",
    "    # sample from the Markov chain.\n",
    "    for i in range(n):\n",
    "        # initial condition.\n",
    "        if i == 0:\n",
    "            solution[0] = initial_state\n",
    "            pass\n",
    "        \n",
    "        else:\n",
    "            current_value = solution[i-1]\n",
    "            solution[i] = markov_chain_sample(cumulative_matrix, current_value, dim)\n",
    "        pass\n",
    "    \n",
    "    return np.array(solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_matrix = np.array([\n",
    "    [.25, .75],\n",
    "    [.4, .6]\n",
    "])\n",
    "initial_state = 0\n",
    "solution = markov_chain(transition_matrix, initial_state, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_of_first_bin = -0.5\n",
    "right_of_last_bin = 2.5\n",
    "\n",
    "plt.hist(solution, np.arange(left_of_first_bin, right_of_last_bin, 1), density = True)\n",
    "plt.title('Markov chain state histogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflective random walks\n",
    "\n",
    "A reflective random walk is a Markov process. Particles in the random walk are bounded on both sides, and move randomly in between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = 0\n",
    "solution = markov_chain(reflective_random_walk, initial_state, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_of_first_bin = -.5\n",
    "right_of_last_bin = 6.5\n",
    "\n",
    "plt.hist(solution, np.arange(left_of_first_bin, right_of_last_bin, 1), density = True)\n",
    "plt.title('Reflective random walk state histogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detailed balance\n",
    "\n",
    "A probability mass function $\\pi$ on $\\mathcal{X}$ satisfies *detailed balance* with respect to a transition matrix $T = (T_{ab})$, if $\\pi_aT_{ab} = \\pi_bT_{ba}$ for all $a, b\\in\\mathcal{X}$. Furthermore, detailed balance implies that $\\pi$ is a stationary distribution, i.e. $\\pi T = \\pi$. Detailed balance is also known as reversibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metropolis Algorithm\n",
    "\n",
    "Consider a pmf $\\pi$ on countable $\\mathcal{X}$ and an observable $\\phi:\\mathcal{X}\\to\\mathbb{R}$. Our goal is to approximate $\\mathbb{E}\\phi(x)$ where $x\\sim\\pi$, and where directly sampling is prohibitively expensive.\n",
    "\n",
    "Let $Q$ be a symmetric, stochastic matrix, termed the *proposal matrix*, such that $Q = (Q_{ab}: a, b\\in\\mathcal{X})$. Let $\\tilde{\\pi} = Z\\pi$. Computing $\\tilde{\\pi}(x)$ without having to compute $Z$ is sufficient in implementing the Metropolis algorithm.\n",
    "\n",
    "The algorithm is described as follows:\n",
    "\n",
    "1. Choose a proposal matrix $Q$,\n",
    "2. Set initial value $x_0\\sim\\mathcal{X}$,\n",
    "3. For $i = 0, \\cdots, n - 1$, sample $x\\sim Q_{x_ix}$ and $u\\sim U(0, 1)$. If $u < \\dfrac{\\tilde{\\pi}(x)}{\\tilde{\\pi}(x_i)}$, then $x_{i + 1} = x$. Otherwise, $x_{i + 1} = x_i$.\n",
    "\n",
    "**Principle**: it is found that the identity matrix $I$ is not a suitable proposal matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modified reflective walk algorithm\n",
    "\n",
    "Let a Markov chain be described by the transition matrix, $T = \\begin{bmatrix}.5 & .5 & 0\\\\.25 & .5 & .25\\\\0 & .5 & .5\\end{bmatrix}$. The matrix is irreducible. Next, there exists a stationary pmf $\\pi = \\begin{bmatrix}.25 & .5 & .25\\end{bmatrix}$. Furthermore, the period for any state is $1$. Therefore, this matrix is ergodic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reflective_walk_modified = np.array([\n",
    "    [.5, .5, .0],\n",
    "    [.25, .5, .25],\n",
    "    [.0, .5, .5]\n",
    "])\n",
    "pi = np.array([[.25, .5, .25]])\n",
    "\n",
    "# we can confirm that pi is indeed stationary with respect to T.\n",
    "np.dot(pi, reflective_walk_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial state.\n",
    "initial_state = 0\n",
    "solution = markov_chain(reflective_walk_modified, initial_state, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "left_of_first_bin = -.5\n",
    "right_of_last_bin = 3.5\n",
    "plt.hist(solution, np.arange(left_of_first_bin, right_of_last_bin, 1), density = True)\n",
    "plt.title('Modified walk distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let our proposal matrix be $\\begin{bmatrix}.5 & .25 & .25\\\\.25 & .5 & .25\\\\.25 & .25 & .5\\end{bmatrix}$. We can let $\\tilde{\\pi}$ be any pmf proportional to $\\pi$, so let's just have $\\tilde{\\pi} = \\begin{bmatrix} 1 & 2 & 1\\end{bmatrix}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposal_matrix = np.array([\n",
    "    [.5, .25, .25],\n",
    "    [.25, .5, .25],\n",
    "    [.25, .25, .5]\n",
    "])\n",
    "\n",
    "pi_tilde = np.array([[1, 2, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = 0\n",
    "cumulative_matrix = markov_chain_cumulative_matrix(proposal_matrix)\n",
    "dim = len(proposal_matrix)\n",
    "\n",
    "# solution set.\n",
    "solution = [None for _ in range(n)]\n",
    "\n",
    "# compute solution.\n",
    "for i in range(n):\n",
    "    if i == 0:\n",
    "        solution[0] = initial_state\n",
    "        pass\n",
    "    else:\n",
    "        current_value = solution[i-1]\n",
    "        x = markov_chain_sample(cumulative_matrix, current_value, dim)\n",
    "        u = np.random.uniform(0, 1)\n",
    "\n",
    "        if u <= pi_tilde[0][x] / pi_tilde[0][current_value]:\n",
    "            solution[i] = x\n",
    "            pass\n",
    "        else:\n",
    "            solution[i] = current_value\n",
    "            pass\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_of_first_bin = -.5\n",
    "right_of_last_bin = 3.5\n",
    "\n",
    "plt.hist(solution, np.arange(left_of_first_bin, right_of_last_bin, 1), density = True)\n",
    "plt.title('Modified walk distribution (Metropolis)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metropolis-Hastings Algorithm\n",
    "\n",
    "Let $f(x)$ be proportional to the target density up to a normalizing constant, and set the current value $x^j$. We sample from the proposal density $x^*\\sim q(x\\vert x^j)$. The probability that $x^*$ is accepted is $\\rho(x^j, x^*) = \\min\\bigg\\{1, \\dfrac{f(x^*)}{f(x^j)}\\dfrac{q(x^j\\vert x^*)}{q(x^*\\vert x^j)}\\bigg\\}$. If $x^*$ is accepted, then $x^{j+1} = x^*$; otherwise $x^{j+1} = x^j$.\n",
    "\n",
    "**Demonstration**: consider the truncated normal distribution $N(5, 9)I(1\\leq x\\leq 6)$. The unnormalized target density is $f(x)\\propto\\exp(-(x-5)^2/18)I(1\\leq x\\leq 6)$, and we choose a proposal distribution $q(x\\vert x^j) = N(x\\vert x^j, 1)$ and let $x^0 = 5$. (Video: [Niemi](https://www.youtube.com/watch?v=VGRVRjr0vyw))\n",
    "\n",
    "**Principle**: the Metropolis algorithm and Metropolis-Hastings algorithm do not provide independent samples. It's recommended to try other algorithms which do provide independent samples, before using the MH algorithm. The advantage of these methods is that we do not need to find a normalization constant $N$ or partition function $Z$ to approximate expectations, which is not the case in the accept-reject algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_constant = integrate.quad(lambda x:np.exp(-(x-5)**2/18)*(1<x<6), 1, 6)[0]\n",
    "def target_dist(x):\n",
    "    if isinstance(x, np.ndarray):\n",
    "        return np.array([target_dist(_x) for _x in x])\n",
    "    return np.exp(-(x-5)**2/18)*(1<x<6)/normalization_constant\n",
    "\n",
    "proposal_dist = lambda x, mu:np.exp(-(x-mu)**2)\n",
    "proposal_dist_sample = lambda x:np.random.normal(x, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metropolis_hastings_random_walk(m):\n",
    "    # this is a demonstration function.\n",
    "    # m is the number of trials.\n",
    "    x_init = 5\n",
    "    solution = [None for _ in range(m)]\n",
    "    for i in range(m):\n",
    "        if i == 0:\n",
    "            solution[0] = x_init\n",
    "            pass\n",
    "        else:\n",
    "            current_value = solution[i-1]\n",
    "            sampled_value = proposal_dist_sample(current_value)\n",
    "            acceptance_probability = min(1, (target_dist(sampled_value)*proposal_dist(current_value, sampled_value))/(target_dist(current_value)*proposal_dist(sampled_value, current_value)))\n",
    "            u = np.random.uniform(0, 1)\n",
    "            # conditions for accept.\n",
    "            if u <= acceptance_probability:\n",
    "                solution[i] = sampled_value\n",
    "                pass\n",
    "            # conditions for reject.\n",
    "            else:\n",
    "                solution[i] = current_value\n",
    "                pass\n",
    "            pass\n",
    "        pass\n",
    "    return solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison of the Metropolis-Hastings algorithm at different densities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xx = np.linspace(1, 6, 100)\n",
    "\n",
    "s = 6 # number of densities.\n",
    "i = 1 # initial subplot index\n",
    "\n",
    "f, axs = plt.subplots(2,2,figsize=(6.4 * 2, 4.8 * s))\n",
    "\n",
    "for k in range(1, s + 1):\n",
    "    solution = metropolis_hastings_random_walk(10 ** k)\n",
    "    \n",
    "    plt.subplot(s, 2, i)\n",
    "    plt.plot(solution, range(10 ** k))\n",
    "    plt.title('Evolution ({} iterations)'.format(10 ** k))\n",
    "    i += 1\n",
    "    \n",
    "    plt.subplot(s, 2, i)\n",
    "    plt.hist(solution, 100, density = True)\n",
    "    plt.step(xx, target_dist(xx), label = 'target')\n",
    "    plt.title('Histogram ({} iterations)'.format(10**k))\n",
    "    plt.legend()\n",
    "    i += 1\n",
    "    pass\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Independent Metropolis-Hastings proposal\n",
    "\n",
    "Suppose $q(x\\vert x^j) = q(x)$, then $q$ is *independent* and the acceptance probability reduces to $\\rho(x^j, x^*) = \\min\\bigg\\{1, \\dfrac{f(x^*)}{f(x^j)}\\dfrac{q(x^j)}{q(x^*)}\\bigg\\}$. The independent Metropolis-Hastings algorithm is otherwise structured similarly to the general version."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
