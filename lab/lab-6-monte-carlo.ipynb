{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mpl_toolkits.mplot3d\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10 ** 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rejection Sampling\n",
    "\n",
    "Sampling from the uniform distribution $X\\sim U(a, b)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.uniform(0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling from an arbitrary function $X\\sim\\rho$, where $\\rho$ is a density defined on the finite, connected domain $(a, b)$. This uses principles of *rejection sampling*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_arbitrary_function(rho, a, b, \n",
    "                              n = 1, \n",
    "                              phi = lambda x:x,\n",
    "                              sampling = np.random.uniform):\n",
    "    # phi is some operation.\n",
    "    \n",
    "    if n == 1:\n",
    "        rejected = True\n",
    "        while rejected:\n",
    "            \n",
    "            # different sampling methods can be chosen here.\n",
    "            x = sampling(a, b)\n",
    "            \n",
    "            # case of acceptance.\n",
    "            if rho(x) >= np.random.uniform(0, 1):\n",
    "                rejected = False\n",
    "                return phi(x)\n",
    "            \n",
    "            pass\n",
    "        pass\n",
    "    else:\n",
    "        return np.array([sample_arbitrary_function(rho, a, b, n = 1, phi = phi) for _ in range(n)])\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstration with the sine function, defined on $(0, \\pi)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = lambda x:1/2*np.sin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_arbitrary_function(p, 0, np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = 0, np.pi\n",
    "\n",
    "solution = sample_arbitrary_function(p, a, b, n = n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(solution, 50, density = True)\n",
    "\n",
    "xx = np.linspace(0, np.pi, 100)\n",
    "plt.plot(xx, p(xx))\n",
    "\n",
    "plt.title('Histogram')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte Carlo approximation\n",
    "\n",
    "Let $x_1, \\cdots, x_n\\sim p$, then the sample mean $\\hat{\\mu}_n = \\dfrac{1}{n}\\sum_{i = 1}^n\\phi(x_i)$ is a basic Monte Carlo estimator of $\\mathbb{E}\\phi(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importance sampling\n",
    "\n",
    "Let $X\\sim p$. Then the expectation $\\mathbb{E}\\phi(x) = \\int_\\Omega\\phi(x)p(x)dx\\approx\\dfrac{1}{n}\\sum_{i = 1}^n\\phi(x_i)$. Let $q(x)$ be a proposal density such that $q(x) = 0$ if and only if $p(x) = 0$ (absolute continuity). Then $\\mathbb{E}\\phi(x) \\approx\\dfrac{1}{n}\\sum_{i = 1}^n\\phi(y_i)w(y_i)$, where $w(y) = \\dfrac{p(y)}{q(y)}$ and $Y\\sim q$.\n",
    "\n",
    "**Principle**: choose $q(x)$ such that $q(x)\\propto\\vert\\phi(x)\\vert p(x)$, i.e. $q$ places more weight on regions where $\\vert\\phi(x)\\vert p(x)$ is large.\n",
    "\n",
    "However, usually we can't find such an exact $q$. Because if we did, we would have also found the partition function of $\\phi(x)p(x)$, and that would be the desired expectation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstration\n",
    "\n",
    "From the density $p(x) = \\dfrac{1}{2}\\sin(x)$ we sample $X$. Let $\\phi(x) = x^2$. We first find the expectation $\\mathbb{E}\\phi(x)$ analytically, and yield $\\dfrac{1}{2}(\\pi^2-4)$. Next, we sample the approximation directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theoretical_expectation = 1/2*(np.pi**2 - 4)\n",
    "print(theoretical_expectation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = lambda x:np.power(x, 2)\n",
    "\n",
    "direct_sample = sample_arbitrary_function(p, a, b, n = n, phi = phi)\n",
    "plt.hist(direct_sample, 50, density = True)\n",
    "plt.show()\n",
    "\n",
    "direct_sample_mean = np.average(direct_sample)\n",
    "\n",
    "print('Sample from direct average: {}'.format(direct_sample_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $q(x) \\propto \\vert\\phi(x)\\vert p(x) = \\dfrac{x^2}{2}\\sin(x)$ be a density function, then $q =\\dfrac{\\sin(x)}{2Z}$, where the partition function $Z = \\dfrac{\\pi^2 - 4}{2}$, is a legal density function. We can varify absolute continuity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = lambda x:np.power(x, 2)/(np.power(np.pi, 2) - 4)*np.sin(x)\n",
    "\n",
    "new_sampling = lambda a, b:sample_arbitrary_function(q, a, b)\n",
    "sample = sample_arbitrary_function(q, a, b, n = n, sampling = new_sampling)\n",
    "\n",
    "plt.hist(sample, 50, density = True)\n",
    "\n",
    "xx = np.linspace(0, np.pi)\n",
    "plt.plot(xx, q(xx))\n",
    "\n",
    "plt.title('Map of proposal density function')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that we defined $q(x) = Z^{-1}\\phi(x)p(x)$. Therefore, $\\mathbb{E}\\phi(x) = \\dfrac{1}{n}\\sum_{i = 1}^n\\phi(x_i)w(x_i) = \\dfrac{\\pi^2 - 4}{2}$ is trivially obtained. In this case, our sampling does not influence the outcome of the result, since $\\phi w$ is a constant function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov Chain Monte Carlo\n",
    "\n",
    "A Markov chain which is irreducible, has a stationary distribution $\\pi$, and is aperiodic, is an *ergodic* Markov chain.\n",
    "\n",
    "I think [Wikipedia](https://en.wikipedia.org/wiki/Markov_chain) explains aperiodicity best:\n",
    "\n",
    "> A state $i$ has period $k$, if any return to state $i$ must occur in multiples of $k$ time steps. [...] If $k = 1$, then the state is said to be *aperiodic*.\n",
    "\n",
    "Also refer to this [post](https://math.stackexchange.com/questions/1227869/period-of-a-markov-chain-why-is-this-one-aperiodic) on my shared misconception with the asker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markov chain model algorithm\n",
    "\n",
    "We design an algorithm modeling the movement of a particle in a Markov chain with an $n\\times n$ transition matrix $M$.\n",
    "\n",
    "Suppose we have a Markov matrix $M = \\begin{bmatrix}.25 & .75\\\\.4 & .6\\end{bmatrix}$, then a cumulative probability matrix is $C = \\begin{bmatrix}.25 & 1\\\\.4 & 1\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def markov_chain_cumulative_matrix(transition_matrix):\n",
    "    n = len(transition_matrix)\n",
    "    solution = [[None for _ in range(n)] for _ in range(n)]\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if j == 0:\n",
    "                solution[i][0] = transition_matrix[i][0]\n",
    "                pass\n",
    "            else:\n",
    "                solution[i][j] = solution[i][j-1] + transition_matrix[i][j]\n",
    "                pass\n",
    "            pass\n",
    "        pass\n",
    "    return np.array(solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A demonstration of the cumulative matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markov_chain_cumulative_matrix(np.array([\n",
    "    [.25, .75],\n",
    "    [.4, .6]\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reflective random walk matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reflective_random_walk = np.array([\n",
    "    [.0, 1., 0., 0., .0, .0],\n",
    "    [.5, .0, .5, .0, .0, .0],\n",
    "    [.0, .5, .0, .5, .0, .0],\n",
    "    [.0, .0, .5, .0, .5, .0],\n",
    "    [.0, .0, .0, .5, .0, .5],\n",
    "    [.0, .0, .0, .0, 1., .0]\n",
    "])\n",
    "\n",
    "markov_chain_cumulative_matrix(reflective_random_walk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def markov_chain(transition_matrix, initial_state, n):\n",
    "    cumulative_matrix = markov_chain_cumulative_matrix(transition_matrix)\n",
    "    \n",
    "    # standardize arguments.\n",
    "    transition_matrix = np.array(transition_matrix)\n",
    "    \n",
    "    # construct solution space.\n",
    "    solution = [None for _ in range(n)]\n",
    "    \n",
    "    # sample from the Markov chain.\n",
    "    for i in range(n):\n",
    "        # initial condition.\n",
    "        if i == 0:\n",
    "            solution[0] = initial_state\n",
    "            pass\n",
    "        \n",
    "        else:\n",
    "            current_value = solution[i-1]\n",
    "            # recall that the current value also corresponds to the index of a specific state in the Markov chain.\n",
    "            # we extract the cumulative probabilities here.\n",
    "            cumulative_probabilities = cumulative_matrix[current_value]\n",
    "            \n",
    "            # sample a random number between 0 and 1.\n",
    "            candidate = np.random.uniform(0, 1)\n",
    "            \n",
    "            # find the greatest lower bound of candidate in cumulative_probabilities.\n",
    "            for j in range(n - 1):\n",
    "                \n",
    "                if candidate <= cumulative_probabilities[j]:\n",
    "                    solution[i] = j\n",
    "                    break\n",
    "                    \n",
    "                    pass\n",
    "                \n",
    "                # last case.\n",
    "                solution[n-1] = n-1\n",
    "                \n",
    "                pass\n",
    "            pass\n",
    "        pass\n",
    "    \n",
    "    return np.array(solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_matrix = np.array([\n",
    "    [.25, .75],\n",
    "    [.4, .6]\n",
    "])\n",
    "initial_state = 0\n",
    "solution = markov_chain(transition_matrix, initial_state, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_of_first_bin = -0.5\n",
    "right_of_last_bin = 2.5\n",
    "\n",
    "plt.hist(solution, np.arange(left_of_first_bin, right_of_last_bin, 1), density = True)\n",
    "plt.title('Markov chain state histogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflective random walks\n",
    "\n",
    "A reflective random walk is a Markov process. Particles in the random walk are bounded on both sides, and move randomly in between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = 0\n",
    "solution = markov_chain(reflective_random_walk, initial_state, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_of_first_bin = -.5\n",
    "right_of_last_bin = 6.5\n",
    "\n",
    "plt.hist(solution, np.arange(left_of_first_bin, right_of_last_bin, 1), density = True)\n",
    "plt.title('Reflective random walk state histogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
